use acir::native_types::{WitnessMap, WitnessStack};
use ark_bn254::Bn254;
use ark_ff::PrimeField;
use clap::{Parser, ValueEnum};
use co_acvm::{PlainAcvmSolver, solver::PlainCoSolver};
use co_builder::flavours::ultra_flavour::UltraFlavour;
use co_builder::prelude::Serialize as FieldSerialize;
use co_noir::HonkRecursion;
use co_ultrahonk::{
    PlainCoBuilder,
    prelude::{
        CoUltraHonk, CrsParser, PlainUltraHonkDriver, Poseidon2Sponge, ProvingKey, UltraHonk,
        Utils, VerifyingKey, ZeroKnowledge,
    },
};
use color_eyre::eyre::Context;
use figment::{
    Figment,
    providers::{Env, Format, Serialized, Toml},
};
use mpc_core::gadgets::poseidon2::Poseidon2;
use noirc_artifacts::program::ProgramArtifact;
use serde::{Deserialize, Serialize};
use sha3::Keccak256;
use std::{
    io::{BufWriter, Write},
    path::PathBuf,
    process::ExitCode,
};

/// Error type for config parsing and merging
#[derive(thiserror::Error, Debug)]
#[error(transparent)]
pub struct ConfigError(#[from] figment::error::Error);

/// An enum representing the transcript hasher to use.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ValueEnum)]
#[clap(rename_all = "lower")]
pub enum TranscriptHash {
    /// The Poseidon2 sponge hash function
    POSEIDON2,
    // The Keccak256 hash function
    KECCAK,
}

/// Cli arguments
#[derive(Parser, Debug, Default, Serialize)]
pub struct Cli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the prover crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub prover_crs: Option<PathBuf>,
    /// The path to the verifier crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub verifier_crs: Option<PathBuf>,
    /// The path to the input file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub input: Option<PathBuf>,
    /// The path to the circuit file, generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<PathBuf>,
    /// The transcript hasher to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub hasher: Option<TranscriptHash>,
    /// The path to the (existing) output directory
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out_dir: Option<PathBuf>,
    /// Prove with or without the zero knowledge property
    #[arg(long)]
    pub zk: bool,
    /// The path to the witness share file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub witness: Option<PathBuf>,
}

/// Config
#[derive(Debug, Deserialize)]
pub struct Config {
    /// The path to the prover crs file
    pub prover_crs: PathBuf,
    /// The path to the verifier crs file
    pub verifier_crs: PathBuf,
    /// The path to the input file
    pub input: PathBuf,
    /// The path to the circuit file
    pub circuit: PathBuf,
    /// The transcript hasher to be used
    pub hasher: TranscriptHash,
    /// The output file where the final witness share is written to
    pub out_dir: PathBuf,
    /// Prove with or without the zero knowledge property
    pub zk: bool,
    /// The path to the witness file, if not passed it will get computed with the plaindriver
    pub witness: Option<PathBuf>,
}

/// Prefix for config env variables
pub const CONFIG_ENV_PREFIX: &str = "CONOIR_";

impl Config {
    /// Parse config from file, env, cli
    pub fn parse(cli: Cli) -> Result<Self, Box<figment::error::Error>> {
        if let Some(path) = &cli.config {
            Ok(Figment::new()
                .merge(Toml::file(path))
                .merge(Env::prefixed(CONFIG_ENV_PREFIX))
                .merge(Serialized::defaults(cli))
                .extract()?)
        } else {
            Ok(Figment::new()
                .merge(Env::prefixed(CONFIG_ENV_PREFIX))
                .merge(Serialized::defaults(cli))
                .extract()?)
        }
    }
}

fn install_tracing() {
    use tracing_subscriber::prelude::*;
    use tracing_subscriber::{EnvFilter, fmt};

    let fmt_layer = fmt::layer()
        .with_target(false)
        .with_line_number(false)
        .with_timer(());
    let filter_layer = EnvFilter::try_from_default_env()
        .or_else(|_| EnvFilter::try_new("info"))
        .unwrap();

    tracing_subscriber::registry()
        .with(filter_layer)
        .with(fmt_layer)
        .init();
}

fn witness_map_to_witness_vector<F: PrimeField>(witness_map: WitnessMap<F>) -> Vec<F> {
    let mut wv = Vec::new();
    let mut index = 0;
    for (w, f) in witness_map.into_iter() {
        // ACIR uses a sparse format for WitnessMap where unused witness indices may be left unassigned.
        // To ensure that witnesses sit at the correct indices in the `WitnessVector`, we fill any indices
        // which do not exist within the `WitnessMap` with the dummy value of zero.
        while index < w.0 {
            wv.push(F::zero());
            index += 1;
        }
        wv.push(f);
        index += 1;
    }
    wv
}

fn convert_witness<F: PrimeField>(mut witness_stack: WitnessStack<F>) -> Vec<F> {
    let witness_map = witness_stack
        .pop()
        .expect("Witness should be present")
        .witness;
    for (key, val) in witness_map.clone().into_iter().skip(6) {
        println!("Witness {}: {val:?}", key.0);
    }
    witness_map_to_witness_vector(witness_map)
}

fn plain_code<const N: usize>(input_path: &PathBuf, program_artifact: &ProgramArtifact) {
    let inputs = PlainCoSolver::read_abi_bn254(input_path, &program_artifact.abi).unwrap();

    // Input parsing
    let leaf = *inputs.get_index(0).unwrap();
    let key_bits = (0..N)
        .map(|i| *inputs.get_index(i as u32 + 1).unwrap())
        .collect::<Vec<_>>();
    let hash_path = (0..N)
        .map(|i| *inputs.get_index(i as u32 + N as u32 + 1).unwrap())
        .collect::<Vec<_>>();

    let mut result_witness = Vec::new();
    result_witness.push(leaf);
    result_witness.extend_from_slice(&key_bits);
    result_witness.extend_from_slice(&hash_path);
    let output_index = result_witness.len();
    result_witness.push(Default::default()); // Placeholder for the output

    let poseidon2 = Poseidon2::<ark_bn254::Fr, 2, 5>::default();

    // The actual program
    let mut current = leaf;
    for i in 0..N {
        let path_bit = key_bits[i];
        let path_hash = hash_path[i];

        let mul = path_bit * (path_hash - current);
        let hash_left = mul + current;
        let hash_right = path_hash - mul;

        current = poseidon2.permutation(&[hash_left, hash_right])[0] + hash_left;
        println!("current: {current:?}");

        println!("mul: {mul}, hash_left: {hash_left}, hash_right: {hash_right}",);
    }

    result_witness[output_index] = current;

    println!();

    for (i, witness) in result_witness.into_iter().enumerate() {
        println!("Result {i},  {witness:?}");
    }

    println!();
}

fn main() -> color_eyre::Result<ExitCode> {
    install_tracing();

    let args = Cli::parse();
    let config = Config::parse(args)?;

    let prover_crs_path = config.prover_crs;
    let verifier_crs_path = config.verifier_crs;
    let input_path = config.input;
    let circuit_path = config.circuit;
    let hasher = config.hasher;
    let out_dir = config.out_dir;
    let witness_file = config.witness;
    let has_zk = ZeroKnowledge::from(config.zk);

    // Read circuit
    let program_artifact = Utils::get_program_artifact_from_file(&circuit_path)
        .context("while parsing program artifact")?;
    let constraint_system = Utils::get_constraint_system_from_artifact(&program_artifact, true);

    plain_code::<2>(&input_path, &program_artifact);

    // Create witness
    let witness = if let Some(witness_path) = witness_file {
        Utils::get_witness_from_file(&witness_path).expect("failed to parse witness")
    } else {
        let solver = PlainCoSolver::init_plain_driver(program_artifact, input_path)
            .context("while initializing plain driver")?;
        let witness = solver.solve().context("while solving")?;
        convert_witness(witness)
    };

    // Build the circuit
    let mut driver = PlainAcvmSolver::new();
    let builder = PlainCoBuilder::<Bn254>::create_circuit(
        &constraint_system,
        false, // We don't support recursive atm
        0,
        witness,
        HonkRecursion::UltraHonk,
        &mut driver,
    )
    .context("while creating the circuit")?;
    // Read the Crs
    let crs_size = co_noir::compute_circuit_size::<Bn254>(&constraint_system, false)?;
    let crs = CrsParser::get_crs(&prover_crs_path, &verifier_crs_path, crs_size, has_zk)?;
    let (prover_crs, verifier_crs) = crs.split();
    // Create the proving key and the barretenberg-compatible verifying key
    let (proving_key, vk_barretenberg) =
        ProvingKey::create_keys_barretenberg(0, builder, &prover_crs, &mut driver)
            .context("While creating keys")?;

    // Write the vk to a file
    let out_path = out_dir.join("vk_plaindriver");
    let mut out_file = BufWriter::new(
        std::fs::File::create(&out_path).context("while creating output file for vk")?,
    );
    let vk_u8 = match hasher {
        TranscriptHash::POSEIDON2 => vk_barretenberg.to_buffer(),
        TranscriptHash::KECCAK => vk_barretenberg.to_buffer_keccak(),
    };
    out_file
        .write(vk_u8.as_slice())
        .context("while writing vk to file")?;
    tracing::info!("Wrote vk to file {}", out_path.display());

    // Create the proof
    let (proof, public_inputs) = match hasher {
        TranscriptHash::POSEIDON2 => CoUltraHonk::<
            PlainUltraHonkDriver,
            _,
            Poseidon2Sponge,
            UltraFlavour,
        >::prove(proving_key, &prover_crs, has_zk)
        .context("While creating proof")?,
        TranscriptHash::KECCAK => {
            CoUltraHonk::<PlainUltraHonkDriver, _, Keccak256, UltraFlavour>::prove(
                proving_key,
                &prover_crs,
                has_zk,
            )
            .context("While creating proof")?
        }
    };
    // Write the proof to a file
    let out_path = out_dir.join("proof_plaindriver");
    let mut out_file = BufWriter::new(
        std::fs::File::create(&out_path).context("while creating output file for proof")?,
    );
    let proof_u8 = proof.to_buffer();
    out_file
        .write(proof_u8.as_slice())
        .context("while writing proof to file")?;
    tracing::info!("Wrote proof to file {}", out_path.display());

    // Write the public inputs to a file
    let out_path = out_dir.join("public_inputs_plaindriver");
    let mut out_file = BufWriter::new(
        std::fs::File::create(&out_path).context("while creating output file for proof")?,
    );
    let public_inputs_u8 = FieldSerialize::to_buffer(&public_inputs, false);
    out_file
        .write(public_inputs_u8.as_slice())
        .context("while writing proof to file")?;
    tracing::info!("Wrote public inputs to file {}", out_path.display());

    // Get the verifying key
    let verifying_key = VerifyingKey::from_barrettenberg_and_crs(vk_barretenberg, verifier_crs);

    // Verify the proof
    let is_valid = match hasher {
        TranscriptHash::POSEIDON2 => UltraHonk::<_, Poseidon2Sponge, UltraFlavour>::verify(
            proof,
            &public_inputs,
            &verifying_key,
            has_zk,
        )
        .context("While verifying proof")?,
        TranscriptHash::KECCAK => UltraHonk::<_, Keccak256, UltraFlavour>::verify(
            proof,
            &public_inputs,
            &verifying_key,
            has_zk,
        )
        .context("While verifying proof")?,
    };

    if is_valid {
        tracing::info!("Proof verified successfully");
        Ok(ExitCode::SUCCESS)
    } else {
        tracing::error!("Proof verification failed");
        Ok(ExitCode::FAILURE)
    }
}
