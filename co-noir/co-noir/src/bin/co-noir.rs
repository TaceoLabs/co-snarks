use ark_bn254::Bn254;
use ark_ff::Zero;
use clap::{Args, Parser, Subcommand, ValueEnum};
use co_acvm::{Rep3AcvmType, solver::Rep3CoSolver};
use co_builder::prelude::Serialize as FieldSerialize;
use co_noir::{NetworkConfig, PubShared};
use co_ultrahonk::prelude::{
    CrsParser, HonkProof, Poseidon2Sponge, ProvingKey, Rep3CoUltraHonk, Rep3UltraHonkDriver,
    ShamirCoUltraHonk, ShamirUltraHonkDriver, UltraHonk, Utils, VerifyingKey,
    VerifyingKeyBarretenberg, ZeroKnowledge,
};
use color_eyre::eyre::{Context, ContextCompat, eyre};
use figment::{
    Figment,
    providers::{Env, Format, Serialized, Toml},
};
use mpc_net::{TcpNetwork, config::NetworkConfigFile};
use serde::{Deserialize, Serialize};
use sha3::Keccak256;
use std::{
    collections::BTreeMap,
    fs::File,
    io::{BufReader, BufWriter, Write},
    path::PathBuf,
    process::ExitCode,
    time::Instant,
};
use tracing::instrument;

/// An enum representing the MPC protocol to use.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ValueEnum)]
#[clap(rename_all = "UPPER")]
pub enum MPCProtocol {
    /// A protocol based on the Replicated Secret Sharing Scheme for 3 parties.
    /// For more information see <https://eprint.iacr.org/2018/403.pdf>.
    REP3,
    /// A protocol based on Shamir Secret Sharing Scheme for n parties.
    /// For more information see <https://iacr.org/archive/crypto2007/46220565/46220565.pdf>.
    SHAMIR,
}

/// An enum representing the transcript hasher to use.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize, ValueEnum)]
#[clap(rename_all = "lower")]
pub enum TranscriptHash {
    /// The Poseidon2 sponge hash function
    POSEIDON2,
    // The Keccak256 hash function
    KECCAK,
}

impl std::fmt::Display for MPCProtocol {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            MPCProtocol::REP3 => write!(f, "REP3"),
            MPCProtocol::SHAMIR => write!(f, "SHAMIR"),
        }
    }
}

impl std::fmt::Display for TranscriptHash {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            TranscriptHash::POSEIDON2 => write!(f, "poseidon2"),
            TranscriptHash::KECCAK => write!(f, "keccak"),
        }
    }
}

/// Cli arguments for `split_witness`
#[derive(Debug, Default, Serialize, Args)]
pub struct SplitWitnessCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the input witness file generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub witness: Option<PathBuf>,
    /// The path to the circuit file, generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<PathBuf>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The path to the (existing) output directory
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out_dir: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    #[arg(short, long, default_value_t = 1)]
    pub threshold: usize,
    /// The number of parties
    #[arg(short, long, default_value_t = 3)]
    pub num_parties: usize,
}

/// Config for `split_witness`
#[derive(Debug, Deserialize)]
pub struct SplitWitnessConfig {
    /// The path to the input witness file generated by Circom
    pub witness: PathBuf,
    /// The path to the circuit file, generated by Noir
    pub circuit: PathBuf,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The path to the (existing) output directory
    pub out_dir: PathBuf,
    /// The threshold of tolerated colluding parties
    pub threshold: usize,
    /// The number of parties
    pub num_parties: usize,
}

/// Cli arguments for `split_input`
#[derive(Debug, Default, Clone, Serialize, Args)]
pub struct SplitInputCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the input JSON file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub input: Option<PathBuf>,
    /// The path to the circuit file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<String>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The path to the (existing) output directory
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out_dir: Option<PathBuf>,
}

/// Config for `split_input`
#[derive(Debug, Clone, Deserialize)]
pub struct SplitInputConfig {
    /// The path to the input JSON file
    pub input: PathBuf,
    /// The path to the circuit file
    pub circuit: String,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The path to the (existing) output directory
    pub out_dir: PathBuf,
}

/// Cli arguments for `split_proving_key`
#[derive(Debug, Default, Serialize, Args)]
pub struct SplitProvingKeyCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the input witness file generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub witness: Option<PathBuf>,
    /// The path to the circuit file, generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<PathBuf>,
    /// The path to the prover crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub crs: Option<PathBuf>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The path to the (existing) output directory
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out_dir: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    #[arg(short, long, default_value_t = 1)]
    pub threshold: usize,
    /// The number of parties
    #[arg(short, long, default_value_t = 3)]
    pub num_parties: usize,
    /// Generate a recursive proof
    #[arg(long)]
    pub recursive: bool,
    /// Prove with or without the zero knowledge property
    #[arg(long)]
    pub zk: bool,
}

/// Config for `split_proving_key`
#[derive(Debug, Deserialize)]
pub struct SplitProvingKeyConfig {
    /// The path to the input witness file generated by Circom
    pub witness: PathBuf,
    /// The path to the circuit file, generated by Noir
    pub circuit: PathBuf,
    /// The path to the prover crs file
    pub crs: PathBuf,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The path to the (existing) output directory
    pub out_dir: PathBuf,
    /// The threshold of tolerated colluding parties
    pub threshold: usize,
    /// The number of parties
    pub num_parties: usize,
    /// Generate a recursive proof
    pub recursive: bool,
    /// Prove with or without the zero knowledge property
    pub zk: bool,
}

/// Cli arguments for `merge_input_shares`
#[derive(Debug, Default, Serialize, Args)]
pub struct MergeInputSharesCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the input JSON file
    #[arg(long)]
    pub inputs: Vec<PathBuf>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The output file where the merged input share is written to
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
}

/// Config for `merge_input_shares`
#[derive(Debug, Deserialize)]
pub struct MergeInputSharesConfig {
    /// The path to the input JSON file
    pub inputs: Vec<PathBuf>,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The output file where the merged input share is written to
    pub out: PathBuf,
}

/// Cli arguments for `generate_witness`
#[derive(Debug, Default, Serialize, Args)]
pub struct GenerateWitnessCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the input share file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub input: Option<PathBuf>,
    /// The path to the circuit file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<String>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The output file where the final witness share is written to
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
}

/// Config for `generate_witness`
#[derive(Debug, Deserialize)]
pub struct GenerateWitnessConfig {
    /// The path to the input share file
    pub input: PathBuf,
    /// The path to the circuit file
    pub circuit: String,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The output file where the final witness share is written to
    pub out: PathBuf,
    /// Network config
    pub network: NetworkConfigFile,
}

/// Cli arguments for `translate_witness`
#[derive(Debug, Serialize, Args)]
pub struct TranslateWitnessCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the witness share file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub witness: Option<PathBuf>,
    /// The MPC protocol that was used for the witness generation
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub src_protocol: Option<MPCProtocol>,
    /// The MPC protocol to be used for the proof generation
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub target_protocol: Option<MPCProtocol>,
    /// The output file where the final witness share is written to
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
}

/// Config for `translate_witness`
#[derive(Debug, Deserialize)]
pub struct TranslateWitnessConfig {
    /// The path to the witness share file
    pub witness: PathBuf,
    /// The MPC protocol that was used for the witness generation
    pub src_protocol: MPCProtocol,
    /// The MPC protocol to be used for the proof generation
    pub target_protocol: MPCProtocol,
    /// The output file where the final witness share is written to
    pub out: PathBuf,
    /// Network config
    pub network: NetworkConfigFile,
}

/// Cli arguments for `translate_witness`
#[derive(Debug, Serialize, Args)]
pub struct TranslateProvingKeyCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the proving_key share file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub proving_key: Option<PathBuf>,
    /// The MPC protocol that was used for the witness generation
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub src_protocol: Option<MPCProtocol>,
    /// The MPC protocol to be used for the proof generation
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub target_protocol: Option<MPCProtocol>,
    /// The output file where the final witness share is written to
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
}

/// Config for `translate_witness`
#[derive(Debug, Deserialize)]
pub struct TranslateProvingKeyConfig {
    /// The path to the proving_key share file
    pub proving_key: PathBuf,
    /// The MPC protocol that was used for the witness generation
    pub src_protocol: MPCProtocol,
    /// The MPC protocol to be used for the proof generation
    pub target_protocol: MPCProtocol,
    /// The output file where the final witness share is written to
    pub out: PathBuf,
    /// Network config
    pub network: NetworkConfigFile,
}

/// Cli arguments for `build_proving_key`
#[derive(Debug, Default, Serialize, Args)]
pub struct BuildProvingKeyCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the witness share file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub witness: Option<PathBuf>,
    /// The path to the circuit file, generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<PathBuf>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The output file where the final proving key is written to.
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    #[arg(short, long, default_value_t = 1)]
    pub threshold: usize,
    /// Generate a recursive proof
    #[arg(long)]
    pub recursive: bool,
}

/// Config for `build_proving_key`
#[derive(Debug, Deserialize)]
pub struct BuildProvingKeyConfig {
    /// The path to the witness share file
    pub witness: PathBuf,
    /// The path to the circuit file, generated by Noir
    pub circuit: PathBuf,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The output file where the final proving key is written to.
    pub out: PathBuf,
    /// The threshold of tolerated colluding parties
    pub threshold: usize,
    /// Network config
    pub network: NetworkConfigFile,
    /// Generate a recursive proof
    pub recursive: bool,
}

/// Cli arguments for `generate_proof`
#[derive(Debug, Serialize, Args)]
pub struct GenerateProofCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the shared proving_key file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub proving_key: Option<PathBuf>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The transcript hasher to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub hasher: Option<TranscriptHash>,
    /// The output file where the final proof is written to. If not passed, this party will not write the proof to a file.
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
    /// The output file where the public inputs are written to. If not passed, this party will not write the public inputs to a file.
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub public_input: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    #[arg(short, long, default_value_t = 1)]
    pub threshold: usize,
    /// Generate a recursive friendly proof
    #[arg(long)]
    pub recursive: bool,
    /// The path to the prover crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub crs: Option<PathBuf>,
    /// Prove with or without the zero knowledge property
    #[arg(long)]
    pub zk: bool,
    /// Write the outputs as fields to json. If not passed, they will only be written as bytes to a file consistent with Barretenberg (if 'out'/'public_input' is specified).
    #[arg(long)]
    pub fields_as_json: bool,
}

/// Config for `generate_proof`
#[derive(Debug, Deserialize)]
pub struct GenerateProofConfig {
    /// The path to the witness share file
    pub proving_key: PathBuf,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The transcript hasher to be used
    pub hasher: TranscriptHash,
    /// The output file where the final proof is written to. If not passed, this party will not write the proof to a file.
    pub out: Option<PathBuf>,
    /// The output file where the public inputs are written to. If not passed, this party will not write the public inputs to a file.
    pub public_input: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    pub threshold: usize,
    /// Network config
    pub network: NetworkConfigFile,
    /// Generate a recursive friendly proof
    pub recursive: bool,
    /// The path to the prover crs file
    pub crs: PathBuf,
    /// Prove with or without the zero knowledge property
    pub zk: bool,
    /// Write the outputs as fields to json. If not passed, they will only be written as bytes to a file consistent with Barretenberg (if 'out'/'public_input' is specified).
    pub fields_as_json: bool,
}

/// Cli arguments for `build_and_generate_proof`
#[derive(Debug, Serialize, Args)]
pub struct BuildAndGenerateProofCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the witness share file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub witness: Option<PathBuf>,
    /// The path to the circuit file, generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<PathBuf>,
    /// The path to the prover crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub crs: Option<PathBuf>,
    /// The MPC protocol to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub protocol: Option<MPCProtocol>,
    /// The transcript hasher to be used
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub hasher: Option<TranscriptHash>,
    /// The output file where the final proof is written to. If not passed, this party will not write the proof to a file.
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub out: Option<PathBuf>,
    /// The output file where the public inputs are written to. If not passed, this party will not write the public inputs to a file.
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub public_input: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    #[arg(short, long, default_value_t = 1)]
    pub threshold: usize,
    /// Generate a recursive proof
    #[arg(long)]
    pub recursive: bool,
    /// Prove with or without the zero knowledge property
    #[arg(long)]
    pub zk: bool,
    /// Write the outputs as fields to json. If not passed, they will only be written as bytes to a file consistent with Barretenberg (if 'out'/'public_input' is specified).
    #[arg(long)]
    pub fields_as_json: bool,
}

/// Config for `build_and_generate_proof`
#[derive(Debug, Deserialize)]
pub struct BuildAndGenerateProofConfig {
    /// The path to the witness share file
    pub witness: PathBuf,
    /// The path to the circuit file, generated by Noir
    pub circuit: PathBuf,
    /// The path to the prover crs file
    pub crs: PathBuf,
    /// The MPC protocol to be used
    pub protocol: MPCProtocol,
    /// The transcript hasher to be used
    pub hasher: TranscriptHash,
    /// The output file where the final proof is written to. If not passed, this party will not write the proof to a file.
    pub out: Option<PathBuf>,
    /// The output file where the public inputs are written to. If not passed, this party will not write the public inputs to a file.
    pub public_input: Option<PathBuf>,
    /// The threshold of tolerated colluding parties
    pub threshold: usize,
    /// Network config
    pub network: NetworkConfigFile,
    /// Generate a recursive proof
    pub recursive: bool,
    /// Prove with or without the zero knowledge property
    pub zk: bool,
    /// Write the outputs as fields to json. If not passed, they will only be written as bytes to a file consistent with Barretenberg (if 'out'/'public_input' is specified).
    pub fields_as_json: bool,
}

/// Cli arguments for `creating_vk`
#[derive(Debug, Serialize, Args)]
pub struct CreateVKCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The transcript hasher used for the proof
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub hasher: Option<TranscriptHash>,
    /// The path to the circuit file, generated by Noir
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub circuit: Option<PathBuf>,
    /// The path to the prover crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub crs: Option<PathBuf>,
    /// The output path to the verification key file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub vk: Option<PathBuf>,
    /// Generate a recursive proof
    #[arg(long)]
    pub recursive: bool,
    /// Write the vk as fields to json. If not passed, the vk will only be written as bytes to a file consistent with Barretenberg.
    #[arg(long)]
    pub fields_as_json: bool,
}

/// Config for `creating_vk`
#[derive(Debug, Deserialize)]
pub struct CreateVKConfig {
    /// The transcript hasher used for the proof, bb uses a different vk for keccak, which misses some fields compared to the non-keccak vk
    pub hasher: TranscriptHash,
    /// The path to the circuit file, generated by Noir
    pub circuit: PathBuf,
    /// The path to the prover crs file
    pub crs: PathBuf,
    /// The path to the verification key file
    pub vk: PathBuf,
    /// Generate a recursive proof
    pub recursive: bool,
    /// Write the vk as fields to json. If not passed, the vk will only be written as bytes to a file consistent with Barretenberg.
    pub fields_as_json: bool,
}

/// Cli arguments for `verify`
#[derive(Debug, Serialize, Args)]
pub struct VerifyCli {
    /// The transcript hasher used for the proof
    #[arg(long, value_enum)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub hasher: Option<TranscriptHash>,
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the proof file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub proof: Option<PathBuf>,
    /// The path to the public_inputs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub public_input: Option<PathBuf>,
    /// The path to the verification key file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub vk: Option<PathBuf>,
    /// The path to the verifier crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub crs: Option<PathBuf>,
    /// Verify a proof with or without the zero knowledge property
    #[arg(long)]
    pub has_zk: bool,
}

/// Config for `verify`
#[derive(Debug, Deserialize)]
pub struct VerifyConfig {
    /// The transcript hasher used for the proof
    pub hasher: TranscriptHash,
    /// The path to the proof file
    pub proof: PathBuf,
    /// The path to the public_inputs file
    pub public_input: PathBuf,
    /// The path to the verification key file
    pub vk: PathBuf,
    /// The path to the verifier crs file
    pub crs: PathBuf,
    /// Verify a proof with or without the zero knowledge property
    pub has_zk: bool,
}

/// Cli arguments for `verify`
#[derive(Debug, Serialize, Args)]
pub struct DownloadCrsCli {
    /// The path to the config file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub config: Option<PathBuf>,
    /// The path to the prover crs file
    #[arg(long)]
    #[serde(skip_serializing_if = "::std::option::Option::is_none")]
    pub crs: Option<PathBuf>,
    /// The number of points to download
    #[arg(short, long, default_value_t = 1)]
    pub num_points: usize,
}

/// Config for `verify`
#[derive(Debug, Deserialize)]
pub struct DownloadCrsConfig {
    /// The path to the prover crs file
    pub crs: PathBuf,
    /// The number of points to download
    pub num_points: usize,
}

/// Prefix for config env variables
pub const CONFIG_ENV_PREFIX: &str = "CONOIR_";

macro_rules! impl_config {
    ($cli: ty, $config: ty) => {
        impl $config {
            /// Parse config from file, env, cli
            pub fn parse(cli: $cli) -> Result<Self, Box<figment::error::Error>> {
                if let Some(path) = &cli.config {
                    Ok(Figment::new()
                        .merge(Toml::file(path))
                        .merge(Env::prefixed(CONFIG_ENV_PREFIX))
                        .merge(Serialized::defaults(cli))
                        .extract()?)
                } else {
                    Ok(Figment::new()
                        .merge(Env::prefixed(CONFIG_ENV_PREFIX))
                        .merge(Serialized::defaults(cli))
                        .extract()?)
                }
            }
        }
    };
}

impl_config!(SplitInputCli, SplitInputConfig);
impl_config!(SplitWitnessCli, SplitWitnessConfig);
impl_config!(SplitProvingKeyCli, SplitProvingKeyConfig);
impl_config!(MergeInputSharesCli, MergeInputSharesConfig);
impl_config!(GenerateWitnessCli, GenerateWitnessConfig);
impl_config!(TranslateWitnessCli, TranslateWitnessConfig);
impl_config!(TranslateProvingKeyCli, TranslateProvingKeyConfig);
impl_config!(BuildProvingKeyCli, BuildProvingKeyConfig);
impl_config!(GenerateProofCli, GenerateProofConfig);
impl_config!(BuildAndGenerateProofCli, BuildAndGenerateProofConfig);
impl_config!(CreateVKCli, CreateVKConfig);
impl_config!(VerifyCli, VerifyConfig);
impl_config!(DownloadCrsCli, DownloadCrsConfig);

#[derive(Parser)]
#[command(version, about, long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Splits an existing witness file generated by noir into secret shares for use in MPC
    SplitWitness(SplitWitnessCli),
    /// Splits a input toml file into secret shares for use in MPC
    SplitInput(SplitInputCli),
    /// Generate the proving key in plain and split it into secret shares used for MPC
    SplitProvingKey(SplitProvingKeyCli),
    /// Merge multiple shared inputs received from multiple parties into a single one
    MergeInputShares(MergeInputSharesCli),
    /// Evaluates the extended witness generation for the specified circuit and input share in MPC
    GenerateWitness(GenerateWitnessCli),
    /// Translates the witness generated with one MPC protocol to a witness for a different one
    TranslateWitness(TranslateWitnessCli),
    /// Translates the proving key generated with one MPC protocol to a proving key for a different one
    TranslateProvingKey(TranslateProvingKeyCli),
    /// Build the proving key for the specified circuit and witness share in MPC
    BuildProvingKey(BuildProvingKeyCli),
    // evaluates the prover algorithm for the specified circuit and shared proving key in MPC
    GenerateProof(GenerateProofCli),
    /// Builds the proving key and evaluates the prover algorithm for the specified circuit and witness share in MPC
    BuildAndGenerateProof(BuildAndGenerateProofCli),
    /// Create a verification key for the specified circuit
    CreateVK(CreateVKCli),
    /// Verification of a Noir proof.
    Verify(VerifyCli),
    /// Download a CRS with a given number of points
    DownloadCrs(DownloadCrsCli),
}

fn install_tracing() {
    use tracing_subscriber::prelude::*;
    use tracing_subscriber::{
        EnvFilter,
        fmt::{self, format::FmtSpan},
    };

    let fmt_layer = fmt::layer()
        .with_target(false)
        .with_line_number(false)
        .with_span_events(FmtSpan::CLOSE | FmtSpan::ENTER);
    let filter_layer = EnvFilter::try_from_default_env()
        .or_else(|_| EnvFilter::try_new("info"))
        .unwrap();

    tracing_subscriber::registry()
        .with(filter_layer)
        .with(fmt_layer)
        .init();
}

fn main() -> color_eyre::Result<ExitCode> {
    install_tracing();
    rustls::crypto::aws_lc_rs::default_provider()
        .install_default()
        .map_err(|_| eyre!("Could not install default rustls crypto provider"))?;
    let args = Cli::parse();

    match args.command {
        Commands::SplitWitness(cli) => {
            let config = SplitWitnessConfig::parse(cli).context("while parsing config")?;
            run_split_witness(config)
        }
        Commands::SplitInput(cli) => {
            let config = SplitInputConfig::parse(cli).context("while parsing config")?;
            run_split_input(config)
        }
        Commands::SplitProvingKey(cli) => {
            let config = SplitProvingKeyConfig::parse(cli).context("while parsing config")?;
            run_split_proving_key(config)
        }
        Commands::MergeInputShares(cli) => {
            let config = MergeInputSharesConfig::parse(cli).context("while parsing config")?;
            run_merge_input_shares(config)
        }
        Commands::GenerateWitness(cli) => {
            let config = GenerateWitnessConfig::parse(cli).context("while parsing config")?;
            run_generate_witness(config)
        }
        Commands::TranslateWitness(cli) => {
            let config = TranslateWitnessConfig::parse(cli).context("while parsing config")?;
            run_translate_witness(config)
        }
        Commands::TranslateProvingKey(cli) => {
            let config = TranslateProvingKeyConfig::parse(cli).context("while parsing config")?;
            run_translate_proving_key(config)
        }
        Commands::BuildProvingKey(cli) => {
            let config = BuildProvingKeyConfig::parse(cli).context("while parsing config")?;
            run_build_proving_key(config)
        }
        Commands::GenerateProof(cli) => {
            let config = GenerateProofConfig::parse(cli).context("while parsing config")?;
            run_generate_proof(config)
        }
        Commands::BuildAndGenerateProof(cli) => {
            let config = BuildAndGenerateProofConfig::parse(cli).context("while parsing config")?;
            run_build_and_generate_proof(config)
        }
        Commands::CreateVK(cli) => {
            let config = CreateVKConfig::parse(cli).context("while parsing config")?;
            run_generate_vk(config)
        }
        Commands::Verify(cli) => {
            let config = VerifyConfig::parse(cli).context("while parsing config")?;
            run_verify(config)
        }
        Commands::DownloadCrs(cli) => {
            let config = DownloadCrsConfig::parse(cli).context("while parsing config")?;
            co_noir::download_g1_crs(config.num_points, &config.crs)?;
            tracing::info!("Downloaded CRS successfully");
            Ok(ExitCode::SUCCESS)
        }
    }
}

#[instrument(level = "debug", skip(config))]
fn run_split_witness(config: SplitWitnessConfig) -> color_eyre::Result<ExitCode> {
    let witness_path = config.witness;
    let circuit_path = config.circuit;
    let protocol = config.protocol;
    let out_dir = config.out_dir;
    let t = config.threshold;
    let n = config.num_parties;

    // parse constraint system
    let program = Utils::get_program_artifact_from_file(&circuit_path)
        .context("while parsing program artifact")?;
    let circuit = &program.bytecode.functions[0];

    // parse witness
    let witness = Utils::get_witness_from_file(&witness_path).context("while parsing witness")?;

    // create witness map storing pub/private information
    let mut witness = witness
        .into_iter()
        .map(PubShared::from_shared)
        .collect::<Vec<_>>();
    for index in circuit
        .public_parameters
        .0
        .iter()
        .chain(circuit.return_values.0.iter())
    {
        let index = index.0 as usize;
        if index >= witness.len() {
            return Err(eyre!("Public input index out of bounds"));
        }
        PubShared::set_public(&mut witness[index]);
    }

    let mut rng = rand::thread_rng();

    tracing::info!("Starting split witness...");
    match protocol {
        MPCProtocol::REP3 => {
            if t != 1 {
                return Err(eyre!("REP3 only allows the threshold to be 1"));
            }
            if n != 3 {
                return Err(eyre!("REP3 only allows the number of parties to be 3"));
            }
            // create witness shares
            let start = Instant::now();
            let shares = co_noir::split_witness_rep3(witness, &mut rng);
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Split witness took {duration_ms} ms");

            // write out the shares to the output directory
            let base_name = witness_path
                .file_name()
                .context("we have a file name")?
                .to_str()
                .context("witness file name is not valid UTF-8")?;
            for (i, share) in shares.iter().enumerate() {
                let path = out_dir.join(format!("{base_name}.{i}.shared"));
                let out_file =
                    BufWriter::new(File::create(&path).context("while creating output file")?);
                bincode::serialize_into(out_file, share)
                    .context("while serializing witness share")?;
                tracing::info!("Wrote witness share {} to file {}", i, path.display());
            }
        }
        MPCProtocol::SHAMIR => {
            // create witness shares
            let start = Instant::now();
            let shares = co_noir::split_witness_shamir(witness, t, n, &mut rng);
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Split witness took {duration_ms} ms");

            // write out the shares to the output directory
            let base_name = witness_path
                .file_name()
                .context("we have a file name")?
                .to_str()
                .context("witness file name is not valid UTF-8")?;
            for (i, share) in shares.iter().enumerate() {
                let path = out_dir.join(format!("{base_name}.{i}.shared"));
                let out_file =
                    BufWriter::new(File::create(&path).context("while creating output file")?);
                bincode::serialize_into(out_file, share)
                    .context("while serializing witness share")?;
                tracing::info!("Wrote witness share {} to file {}", i, path.display());
            }
        }
    }
    tracing::info!("Split witness into shares successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_split_proving_key(config: SplitProvingKeyConfig) -> color_eyre::Result<ExitCode> {
    let witness_path = config.witness;
    let circuit_path = config.circuit;
    let crs_path = config.crs;
    let protocol = config.protocol;
    let out_dir = config.out_dir;
    let t = config.threshold;
    let n = config.num_parties;
    let recursive = config.recursive;
    let has_zk = ZeroKnowledge::from(config.zk);

    // parse constraint system
    let constraint_system = Utils::get_constraint_system_from_file(&circuit_path, true)
        .context("while parsing program artifact")?;
    // parse witness
    let witness = Utils::get_witness_from_file(&witness_path).context("while parsing witness")?;
    let circuit_size = co_noir::compute_circuit_size::<Bn254>(&constraint_system, recursive)?;
    let prover_crs = CrsParser::<Bn254>::get_crs_g1(crs_path, circuit_size, has_zk)?;
    let proving_key = co_noir::generate_proving_key_plain(
        &constraint_system,
        witness,
        prover_crs.into(),
        recursive,
    )?;

    let mut rng = rand::thread_rng();

    tracing::info!("Starting split proving key...");
    match protocol {
        MPCProtocol::REP3 => {
            if t != 1 {
                return Err(eyre!("REP3 only allows the threshold to be 1"));
            }
            if n != 3 {
                return Err(eyre!("REP3 only allows the number of parties to be 3"));
            }

            // create shares
            let start = Instant::now();
            let shares = co_noir::split_proving_key_rep3(proving_key, &mut rng)?;
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Split proving key took {duration_ms} ms");

            // write out the shares to the output directory
            let base_name = "proving_key";
            for (i, share) in shares.into_iter().enumerate() {
                let path = out_dir.join(format!("{base_name}.{i}.shared"));
                let out_file =
                    BufWriter::new(File::create(&path).context("while creating output file")?);
                bincode::serialize_into(out_file, &share)
                    .context("while serializing proving_key share")?;
                tracing::info!("Wrote proving_key share {} to file {}", i, path.display());
            }
        }
        MPCProtocol::SHAMIR => {
            // create shares
            let start = Instant::now();
            let shares = co_noir::split_proving_key_shamir(proving_key, t, n, &mut rng)?;
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Split proving key took {duration_ms} ms");

            // write out the shares to the output directory
            let base_name = "proving_key";
            for (i, share) in shares.into_iter().enumerate() {
                let path = out_dir.join(format!("{base_name}.{i}.shared"));
                let out_file =
                    BufWriter::new(File::create(&path).context("while creating output file")?);
                bincode::serialize_into(out_file, &share)
                    .context("while serializing proving_key share")?;
                tracing::info!("Wrote proving_key share {} to file {}", i, path.display());
            }
        }
    }
    tracing::info!("Split proving keys into shares successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_split_input(config: SplitInputConfig) -> color_eyre::Result<ExitCode> {
    let input = config.input;
    let circuit = config.circuit;
    let protocol = config.protocol;
    let out_dir = config.out_dir;

    if protocol != MPCProtocol::REP3 {
        return Err(eyre!(
            "Only REP3 protocol is supported for splitting inputs"
        ));
    }
    let circuit_path = PathBuf::from(&circuit);

    // parse constraint system
    let compiled_program = Utils::get_program_artifact_from_file(&circuit_path)
        .context("while parsing program artifact")?;

    // read the input file
    let inputs = Rep3CoSolver::<_, ()>::partially_read_abi_bn254_fieldelement(
        &input,
        &compiled_program.abi,
        &compiled_program.bytecode,
    )?;

    // create input shares
    let mut rng = rand::thread_rng();
    tracing::info!("Starting split input...");
    let start = Instant::now();
    let shares = co_noir::split_input_rep3::<Bn254, _>(inputs, &mut rng);
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Split input took {duration_ms} ms");

    // write out the shares to the output directory
    let base_name = input
        .file_name()
        .context("we have a file name")?
        .to_str()
        .context("input file name is not valid UTF-8")?;
    for (i, share) in shares.iter().enumerate() {
        let path = out_dir.join(format!("{base_name}.{i}.shared"));
        let out_file = BufWriter::new(File::create(&path).context("while creating output file")?);
        bincode::serialize_into(out_file, share).context("while serializing input share")?;
        tracing::info!("Wrote input share {} to file {}", i, path.display());
    }

    tracing::info!("Split input into shares successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_merge_input_shares(config: MergeInputSharesConfig) -> color_eyre::Result<ExitCode> {
    let inputs = config.inputs;
    let protocol = config.protocol;
    let out = config.out;

    if protocol != MPCProtocol::REP3 {
        return Err(eyre!(
            "Only REP3 protocol is supported for splitting/merging inputs"
        ));
    }

    if inputs.len() < 2 {
        return Err(eyre!("Need at least two input shares to merge"));
    }

    let input_shares = inputs
        .iter()
        .map(|input| {
            // parse input shares
            let input_share_file =
                BufReader::new(File::open(input).context("while opening input share file")?);
            let input_share: BTreeMap<String, Rep3AcvmType<ark_bn254::Fr>> =
                bincode::deserialize_from(input_share_file)
                    .context("while deserializing input share")?;
            color_eyre::Result::<_>::Ok(input_share)
        })
        .collect::<Result<Vec<_>, _>>()?;

    tracing::info!("Starting input shares merging...");
    let start = Instant::now();
    let result = co_noir::merge_input_shares::<Bn254>(input_shares)?;
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Merge input shares took {duration_ms} ms");

    // write out the shares to the output file
    let out_file = BufWriter::new(File::create(&out).context("while creating output file")?);
    bincode::serialize_into(out_file, &result).context("while serializing witness share")?;
    tracing::info!("Witness successfully written to {}", out.display());

    tracing::info!("Merge input into shares successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_generate_witness(config: GenerateWitnessConfig) -> color_eyre::Result<ExitCode> {
    let input = config.input;
    let circuit = config.circuit;
    let protocol = config.protocol;
    let out = config.out;

    if protocol != MPCProtocol::REP3 {
        return Err(eyre!(
            "Only REP3 protocol is supported for witness generation"
        ));
    }
    let circuit_path = PathBuf::from(&circuit);

    // parse constraint system
    let compiled_program = Utils::get_program_artifact_from_file(&circuit_path)
        .context("while parsing program artifact")?;

    // parse input shares
    let input_share_file =
        BufReader::new(File::open(&input).context("while opening input share file")?);
    let input_share: BTreeMap<String, Rep3AcvmType<ark_bn254::Fr>> =
        bincode::deserialize_from(input_share_file).context("while deserializing input share")?;

    // connect to network
    let network_config = NetworkConfig::try_from(config.network.to_owned())
        .context("while converting network config")?;
    let [net0, net1] =
        TcpNetwork::networks::<2>(network_config).context("while connecting to network")?;

    tracing::info!("Starting witness generation...");
    let start = Instant::now();
    let result_witness_share =
        co_noir::generate_witness_rep3(input_share, compiled_program, &net0, &net1)?;
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Generate witness took {duration_ms} ms");

    // write result to output file
    let out_file = BufWriter::new(std::fs::File::create(&out)?);
    bincode::serialize_into(out_file, &result_witness_share)
        .context("while serializing witness share")?;
    tracing::info!("Witness successfully written to {}", out.display());
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_translate_witness(config: TranslateWitnessConfig) -> color_eyre::Result<ExitCode> {
    let witness = config.witness;
    let src_protocol = config.src_protocol;
    let target_protocol = config.target_protocol;
    let out = config.out;

    if src_protocol != MPCProtocol::REP3 || target_protocol != MPCProtocol::SHAMIR {
        return Err(eyre!("Only REP3 to SHAMIR translation is supported"));
    }

    // parse witness shares
    let witness_file =
        BufReader::new(File::open(witness).context("trying to open witness share file")?);
    let witness_share: Vec<Rep3AcvmType<ark_bn254::Fr>> =
        bincode::deserialize_from(witness_file).context("while deserializing witness share")?;

    // connect to network
    let network_config = NetworkConfig::try_from(config.network.to_owned())
        .context("while converting network config")?;
    let net = TcpNetwork::new(network_config).context("while connecting to network")?;

    // Translate witness to shamir shares
    tracing::info!("Starting witness translation...");
    let start = Instant::now();
    let shamir_witness_shares = co_noir::translate_witness::<Bn254, _>(witness_share, &net)?;
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Translate witness took {duration_ms} ms");

    // write result to output file
    let out_file = BufWriter::new(std::fs::File::create(&out)?);
    bincode::serialize_into(out_file, &shamir_witness_shares)?;
    tracing::info!("Witness successfully written to {}", out.display());
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_translate_proving_key(config: TranslateProvingKeyConfig) -> color_eyre::Result<ExitCode> {
    let proving_key = config.proving_key;
    let src_protocol = config.src_protocol;
    let target_protocol = config.target_protocol;
    let out = config.out;

    if src_protocol != MPCProtocol::REP3 || target_protocol != MPCProtocol::SHAMIR {
        return Err(eyre!("Only REP3 to SHAMIR translation is supported"));
    }

    // parse proving_key shares
    let proving_key_file =
        BufReader::new(File::open(proving_key).context("trying to open witness share file")?);
    let proving_key: ProvingKey<Rep3UltraHonkDriver, Bn254> =
        bincode::deserialize_from(proving_key_file).context("while deserializing witness share")?;

    // connect to network
    let network_config = NetworkConfig::try_from(config.network.to_owned())
        .context("while converting network config")?;
    let net = TcpNetwork::new(network_config).context("while connecting to network")?;

    // Translate proving key to shamir shares
    tracing::info!("Starting proving key translation...");
    let start = Instant::now();
    let shamir_proving_key = co_noir::translate_proving_key(proving_key, &net)?;
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Translate proving key took {duration_ms} ms");

    // write result to output file
    let out_file = BufWriter::new(std::fs::File::create(&out)?);
    bincode::serialize_into(out_file, &shamir_proving_key)?;
    tracing::info!("Proving_key successfully written to {}", out.display());
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_build_proving_key(config: BuildProvingKeyConfig) -> color_eyre::Result<ExitCode> {
    let witness = config.witness;
    let circuit_path = config.circuit;
    let protocol = config.protocol;
    let out = config.out;
    let n = config.network.parties.len();
    let t = config.threshold;
    let recursive = config.recursive;

    // parse witness shares
    let witness_file =
        BufReader::new(File::open(witness).context("trying to open witness share file")?);

    // parse constraint system
    let constraint_system = Utils::get_constraint_system_from_file(&circuit_path, true)
        .context("while parsing program artifact")?;

    // connect to network
    let network_config = NetworkConfig::try_from(config.network.to_owned())
        .context("while converting network config")?;
    let [net0, net1] =
        TcpNetwork::networks::<2>(network_config).context("while connecting to network")?;

    tracing::info!("Starting proving key generation...");
    match protocol {
        MPCProtocol::REP3 => {
            if t != 1 {
                return Err(eyre!("REP3 only allows the threshold to be 1"));
            }
            let witness_share = bincode::deserialize_from(witness_file)
                .context("while deserializing witness share")?;

            let start = Instant::now();
            let proving_key = co_noir::generate_proving_key_rep3(
                &constraint_system,
                witness_share,
                recursive,
                &net0,
                &net1,
            )?;
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Build proving key took {duration_ms} ms");

            // write result to output file
            let out_file = BufWriter::new(std::fs::File::create(&out)?);
            bincode::serialize_into(out_file, &proving_key)?;
            tracing::info!("Proving Key successfully written to {}", out.display());
        }
        MPCProtocol::SHAMIR => {
            let witness_share = bincode::deserialize_from(witness_file)
                .context("while deserializing witness share")?;

            let start = Instant::now();
            let proving_key = co_noir::generate_proving_key_shamir(
                n,
                t,
                &constraint_system,
                witness_share,
                recursive,
                &net0,
            )?;
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Build proving key took {duration_ms} ms");

            // write result to output file
            let out_file = BufWriter::new(std::fs::File::create(&out)?);
            bincode::serialize_into(out_file, &proving_key)?;
            tracing::info!("Proving Key successfully written to {}", out.display());
        }
    };

    tracing::info!("Proving Key generation finished successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_generate_proof(config: GenerateProofConfig) -> color_eyre::Result<ExitCode> {
    let proving_key = config.proving_key;
    let protocol = config.protocol;
    let hasher = config.hasher;
    let out = config.out;
    let public_input_filename = config.public_input;
    let n = config.network.parties.len();
    let t = config.threshold;
    let crs_path = config.crs;
    let fields_as_json = config.fields_as_json;
    let has_zk = ZeroKnowledge::from(config.zk);

    // connect to network
    let network_config = NetworkConfig::try_from(config.network.to_owned())
        .context("while converting network config")?;
    let net = TcpNetwork::new(network_config).context("while connecting to network")?;

    // parse proving_key file
    let proving_key_file =
        BufReader::new(File::open(proving_key).context("trying to open proving_key file")?);

    tracing::info!("Starting proof generation...");
    let (proof, public_input) = match protocol {
        MPCProtocol::REP3 => {
            if t != 1 {
                return Err(eyre!("REP3 only allows the threshold to be 1"));
            }
            // Get the proving key and prover
            let proving_key: ProvingKey<Rep3UltraHonkDriver, Bn254> =
                bincode::deserialize_from(proving_key_file)
                    .context("while deserializing input share")?;
            let prover_crs = CrsParser::<Bn254>::get_crs_g1(
                crs_path,
                proving_key.circuit_size as usize,
                has_zk,
            )?;

            match hasher {
                TranscriptHash::POSEIDON2 => {
                    // execute prover in MPC
                    let start = Instant::now();
                    let (proof, public_inputs) = Rep3CoUltraHonk::<_, Poseidon2Sponge>::prove(
                        &net,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_inputs)
                }
                TranscriptHash::KECCAK => {
                    // execute prover in MPC
                    let start = Instant::now();
                    let (proof, public_inputs) = Rep3CoUltraHonk::<_, Keccak256>::prove(
                        &net,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_inputs)
                }
            }
        }
        MPCProtocol::SHAMIR => {
            // Get the proving key and prover
            let proving_key: ProvingKey<ShamirUltraHonkDriver, Bn254> =
                bincode::deserialize_from(proving_key_file)
                    .context("while deserializing input share")?;
            let prover_crs = CrsParser::<Bn254>::get_crs_g1(
                crs_path,
                proving_key.circuit_size as usize,
                has_zk,
            )?;

            // execute prover in MPC
            match hasher {
                TranscriptHash::POSEIDON2 => {
                    let start = Instant::now();
                    let (proof, public_input) = ShamirCoUltraHonk::<_, Poseidon2Sponge>::prove(
                        &net,
                        n,
                        t,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_input)
                }
                TranscriptHash::KECCAK => {
                    let start = Instant::now();
                    let (proof, public_input) = ShamirCoUltraHonk::<_, Keccak256>::prove(
                        &net,
                        n,
                        t,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_input)
                }
            }
        }
    };

    // write result to output file
    if let Some(ref out) = out {
        let mut out_file =
            BufWriter::new(std::fs::File::create(out).context("while creating output file")?);

        let proof_u8 = proof.to_buffer();
        out_file
            .write(proof_u8.as_slice())
            .context("while writing proof to file")?;
        tracing::info!("Wrote proof to file {}", out.display());
    }

    // write public input to output file
    if let Some(ref public_input_filename) = public_input_filename {
        let mut out_file = BufWriter::new(
            std::fs::File::create(public_input_filename).context("while creating output file")?,
        );

        let public_inputs_u8 = FieldSerialize::to_buffer(&public_input, false);
        out_file
            .write(public_inputs_u8.as_slice())
            .context("while writing proof to file")?;
        tracing::info!(
            "Wrote public inputs to file {}",
            public_input_filename.display()
        );
    }

    // write the proof and public inputs as field elements to a JSON file if flag is set
    if fields_as_json {
        let proof_path = if let Some(out_path) = out {
            out_path.with_extension("json")
        } else {
            PathBuf::from("proof.json")
        };
        let public_inputs_path = if let Some(public_input_path) = public_input_filename {
            public_input_path.with_extension("json")
        } else {
            PathBuf::from("public_input.json")
        };

        let proof_as_strings = proof
            .inner()
            .iter()
            .map(|f| {
                if f.is_zero() {
                    "0".to_string()
                } else {
                    f.to_string()
                }
            })
            .collect::<Vec<String>>();
        let proof_json_file = BufWriter::new(
            std::fs::File::create(&proof_path).context("while creating proof json file")?,
        );
        serde_json::to_writer(proof_json_file, &proof_as_strings)
            .context("while writing out proof to JSON file")?;
        tracing::info!("Wrote proof to file {}", proof_path.display());

        let public_inputs_as_strings = public_input
            .iter()
            .map(|f| {
                if f.is_zero() {
                    "0".to_string()
                } else {
                    f.to_string()
                }
            })
            .collect::<Vec<String>>();
        let public_input_json_file = BufWriter::new(
            std::fs::File::create(&public_inputs_path)
                .context("while creating public input json file")?,
        );
        serde_json::to_writer(public_input_json_file, &public_inputs_as_strings)
            .context("while writing out public inputs to JSON file")?;
        tracing::info!("Wrote public input to file {}", proof_path.display());
    }

    tracing::info!("Proof generation finished successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_build_and_generate_proof(
    config: BuildAndGenerateProofConfig,
) -> color_eyre::Result<ExitCode> {
    let witness = config.witness;
    let circuit_path = config.circuit;
    let crs_path = config.crs;
    let protocol = config.protocol;
    let hasher = config.hasher;
    let out = config.out;
    let public_input_filename = config.public_input;
    let n = config.network.parties.len();
    let t = config.threshold;
    let recursive = config.recursive;
    let fields_as_json = config.fields_as_json;
    let has_zk = ZeroKnowledge::from(config.zk);

    if hasher == TranscriptHash::KECCAK && recursive {
        tracing::warn!("Note that the Poseidon hasher is better suited for recursion");
    }

    // parse witness shares
    let witness_file =
        BufReader::new(File::open(witness).context("trying to open witness share file")?);

    // parse constraint system
    let constraint_system = Utils::get_constraint_system_from_file(&circuit_path, true)
        .context("while parsing program artifact")?;

    // connect to network
    let network_config = NetworkConfig::try_from(config.network.to_owned())
        .context("while converting network config")?;
    let [net0, net1] =
        TcpNetwork::networks::<2>(network_config).context("while connecting to network")?;

    let circuit_size = co_noir::compute_circuit_size::<Bn254>(&constraint_system, recursive)?;
    let prover_crs = CrsParser::get_crs_g1(crs_path, circuit_size, has_zk)?;

    tracing::info!("Starting proving key generation...");
    let (proof, public_input) = match protocol {
        MPCProtocol::REP3 => {
            if t != 1 {
                return Err(eyre!("REP3 only allows the threshold to be 1"));
            }
            let witness_share = bincode::deserialize_from(witness_file)
                .context("while deserializing witness share")?;

            let start = Instant::now();
            let proving_key = co_noir::generate_proving_key_rep3(
                &constraint_system,
                witness_share,
                recursive,
                &net0,
                &net1,
            )?;

            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Build proving key took {duration_ms} ms");

            tracing::info!("Starting proof generation...");
            let (proof, public_input) = match hasher {
                TranscriptHash::POSEIDON2 => {
                    let start = Instant::now();
                    let (proof, public_input) = Rep3CoUltraHonk::<_, Poseidon2Sponge>::prove(
                        &net0,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_input)
                }
                TranscriptHash::KECCAK => {
                    let start = Instant::now();
                    let (proof, public_input) = Rep3CoUltraHonk::<_, Keccak256>::prove(
                        &net0,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_input)
                }
            };
            (proof, public_input)
        }
        MPCProtocol::SHAMIR => {
            let witness_share = bincode::deserialize_from(witness_file)
                .context("while deserializing witness share")?;

            let start = Instant::now();
            let proving_key = co_noir::generate_proving_key_shamir(
                n,
                t,
                &constraint_system,
                witness_share,
                recursive,
                &net0,
            )?;
            let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
            tracing::info!("Build proving key took {duration_ms} ms");

            tracing::info!("Starting proof generation...");
            let (proof, public_input) = match hasher {
                TranscriptHash::POSEIDON2 => {
                    let start = Instant::now();
                    let (proof, public_input) = ShamirCoUltraHonk::<_, Poseidon2Sponge>::prove(
                        &net0,
                        n,
                        t,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_input)
                }
                TranscriptHash::KECCAK => {
                    // execute prover in MPC
                    let start = Instant::now();
                    let (proof, public_input) = ShamirCoUltraHonk::<_, Keccak256>::prove(
                        &net0,
                        n,
                        t,
                        proving_key,
                        &prover_crs,
                        has_zk,
                    )?;
                    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
                    tracing::info!("Generate proof took {duration_ms} ms");
                    (proof, public_input)
                }
            };
            (proof, public_input)
        }
    };

    // write result to output file
    if let Some(ref out) = out {
        let mut out_file =
            BufWriter::new(std::fs::File::create(out).context("while creating output file")?);

        let proof_u8 = proof.to_buffer();
        out_file
            .write(proof_u8.as_slice())
            .context("while writing proof to file")?;
        tracing::info!("Wrote proof to file {}", out.display());
    }

    // write public input to output file
    if let Some(ref public_input_filename) = public_input_filename {
        let mut out_file = BufWriter::new(
            std::fs::File::create(public_input_filename).context("while creating output file")?,
        );

        let public_inputs_u8 = FieldSerialize::to_buffer(&public_input, false);
        out_file
            .write(public_inputs_u8.as_slice())
            .context("while writing public input to file")?;
        tracing::info!(
            "Wrote public inputs to file {}",
            public_input_filename.display()
        );
    }

    // write the proof and public inputs as field elements to a JSON file if flag is set
    if fields_as_json {
        let proof_path = if let Some(out_path) = out {
            out_path.with_extension("json")
        } else {
            PathBuf::from("proof.json")
        };
        let public_inputs_path = if let Some(public_input_path) = public_input_filename {
            public_input_path.with_extension("json")
        } else {
            PathBuf::from("public_input.json")
        };

        let proof_as_strings = proof
            .inner()
            .iter()
            .map(|f| {
                if f.is_zero() {
                    "0".to_string()
                } else {
                    f.to_string()
                }
            })
            .collect::<Vec<String>>();
        let proof_json_file = BufWriter::new(
            std::fs::File::create(&proof_path).context("while creating proof json file")?,
        );
        serde_json::to_writer(proof_json_file, &proof_as_strings)
            .context("while writing out proof to JSON file")?;
        tracing::info!("Wrote proof to file {}", proof_path.display());

        let public_inputs_as_strings = public_input
            .iter()
            .map(|f| {
                if f.is_zero() {
                    "0".to_string()
                } else {
                    f.to_string()
                }
            })
            .collect::<Vec<String>>();
        let public_input_json_file = BufWriter::new(
            std::fs::File::create(&public_inputs_path)
                .context("while creating public input json file")?,
        );
        serde_json::to_writer(public_input_json_file, &public_inputs_as_strings)
            .context("while writing out public inputs to JSON file")?;
        tracing::info!("Wrote public input to file {}", proof_path.display());
    }

    tracing::info!("Proof generation finished successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_generate_vk(config: CreateVKConfig) -> color_eyre::Result<ExitCode> {
    let circuit_path = config.circuit;
    let crs_path = config.crs;
    let vk_path = config.vk;
    let hasher = config.hasher;
    let recursive = config.recursive;
    let fields_as_json = config.fields_as_json;

    if hasher == TranscriptHash::KECCAK && recursive {
        tracing::warn!("Note that the Poseidon hasher is better suited for recursion");
    }

    // parse constraint system
    let constraint_system = Utils::get_constraint_system_from_file(&circuit_path, true)
        .context("while parsing program artifact")?;

    let circuit_size = co_noir::compute_circuit_size::<Bn254>(&constraint_system, recursive)?;
    let prover_crs = CrsParser::get_crs_g1(crs_path, circuit_size, ZeroKnowledge::No)?;

    tracing::info!("Starting to generate verification key...");
    let start = Instant::now();
    let vk = co_noir::generate_vk_barretenberg::<Bn254>(
        &constraint_system,
        prover_crs.into(),
        recursive,
    )?;
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Verfication key generation took {} ms", duration_ms);

    let mut out_file =
        BufWriter::new(std::fs::File::create(&vk_path).context("while creating output file")?);

    // write the verification key as field elements to a JSON file if flag is set
    if fields_as_json {
        let vk_path_json = vk_path.with_extension("json");
        let vk_as_fields = vk.to_field_elements();
        let vk_as_strings = vk_as_fields
            .iter()
            .map(|f| {
                if f.is_zero() {
                    "0".to_string()
                } else {
                    f.to_string()
                }
            })
            .collect::<Vec<String>>();
        let vk_json_file = BufWriter::new(
            std::fs::File::create(&vk_path_json).context("while creating output json file")?,
        );
        serde_json::to_writer(vk_json_file, &vk_as_strings)
            .context("while writing out verification key to JSON file")?;
        tracing::info!("Wrote verification key to file {}", vk_path_json.display());
    }

    let vk_u8 = match hasher {
        TranscriptHash::POSEIDON2 => vk.to_buffer(),
        TranscriptHash::KECCAK => vk.to_buffer_keccak(),
    };
    out_file
        .write(vk_u8.as_slice())
        .context("while writing vk to file")?;
    tracing::info!("Wrote vk to file {}", vk_path.display());

    tracing::info!("Verification key generation finished successfully");
    Ok(ExitCode::SUCCESS)
}

#[instrument(level = "debug", skip(config))]
fn run_verify(config: VerifyConfig) -> color_eyre::Result<ExitCode> {
    let proof = config.proof;
    let public_inputs = config.public_input;
    let vk_path: PathBuf = config.vk;
    let crs_path = config.crs;
    let hasher = config.hasher;
    let has_zk = ZeroKnowledge::from(config.has_zk);

    // parse proof file
    let proof_u8 = std::fs::read(&proof).context("while reading proof file")?;
    let proof = HonkProof::from_buffer(&proof_u8).context("while deserializing proof")?;

    // parse public_inputs file
    let public_inputs_u8 =
        std::fs::read(&public_inputs).context("while reading public_inputs file")?;
    let public_inputs = FieldSerialize::from_buffer(&public_inputs_u8, false)
        .context("while deserializing public_inputs")?;

    // parse the crs
    let verifier_crs = CrsParser::<Bn254>::get_crs_g2(crs_path)?;

    // parse verification key file
    let vk_u8 = std::fs::read(&vk_path).context("while reading vk file")?;
    let vk = VerifyingKeyBarretenberg::<Bn254>::from_buffer(&vk_u8)
        .context("while deserializing verification key")?;

    let vk = VerifyingKey::from_barrettenberg_and_crs(vk, verifier_crs);
    // The actual verifier
    tracing::info!("Starting proof verification...");
    let start = Instant::now();
    let res = match hasher {
        TranscriptHash::POSEIDON2 => {
            UltraHonk::<_, Poseidon2Sponge>::verify(proof, &public_inputs, &vk, has_zk)
                .context("while verifying proof")?
        }
        TranscriptHash::KECCAK => {
            UltraHonk::<_, Keccak256>::verify(proof, &public_inputs, &vk, has_zk)
                .context("while verifying proof")?
        }
    };
    let duration_ms = start.elapsed().as_micros() as f64 / 1000.;
    tracing::info!("Verify took {} ms", duration_ms);

    if res {
        tracing::info!("Proof verified successfully");
        Ok(ExitCode::SUCCESS)
    } else {
        tracing::error!("Proof verification failed");
        Ok(ExitCode::FAILURE)
    }
}
